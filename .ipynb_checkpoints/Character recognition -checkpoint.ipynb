{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec94324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gt.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cv2 \n",
    "import os \n",
    "import torch \n",
    "import matplotlib.pyplot as  plt\n",
    "files = os.listdir('train')\n",
    "trainfile = [i for i in files if '.txt' in i ]\n",
    "trainfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7a40af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\82108\\.conda\\envs\\torchenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train/'+trainfile[0], '\\t', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5d7e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000/image_0.jpg</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001/image_1.jpg</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002/image_2.jpg</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003/image_3.jpg</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004/image_4.jpg</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file label\n",
       "0  0000/image_0.jpg     A\n",
       "1  0001/image_1.jpg     B\n",
       "2  0002/image_2.jpg     C\n",
       "3  0003/image_3.jpg     D\n",
       "4  0004/image_4.jpg     E"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns= ['file', 'label']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0485e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# this  chart  shows that number of  all characters are equally distributed  \n",
    "train.groupby('label').count().hist(bins = 100 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98fd899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2415"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length  of  all characters \n",
    "len(set(train['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a588e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TorchvisionDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read an image with PIL\n",
    "        image = Image.open(file_path)\n",
    "        \n",
    "        start_t = time.time()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        total_time = (time.time() - start_t)\n",
    "\n",
    "        return image, label, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a930cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Albumentation is faster I'll use Albumentation as augmentation tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsDataset(Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read an image with OpenCV\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        # By default OpenCV uses BGR color space for color images,\n",
    "        # so we need to convert the image to RGB color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        start_t = time.time()\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image) \n",
    "            image = augmented['image']\n",
    "\t    total_time = (time.time() - start_t)\n",
    "        return image, label, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbfdec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
